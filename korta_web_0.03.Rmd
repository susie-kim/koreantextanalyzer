---
title: "korta: Korean Text Analyzer"
output:
  flexdashboard::flex_dashboard:
    orientation: rows
    vertical_layout: fill
    css: style.css
runtime: shiny
resource_files:
- .Rprofile
---

```{r setup, include=FALSE}
library(shiny)
library(flexdashboard)
library(tidyverse)
library(DT)
library(wordcloud2)
library(mailtoR)
library(ggthemr)
ggthemr('flat')

# Define any Python packages needed for the app here:
PYTHON_DEPENDENCIES = c('pandas', 'konlpy')
virtualenv_dir = Sys.getenv('VIRTUALENV_NAME')
python_path = Sys.getenv('PYTHON_PATH')

# Create virtual env and install dependencies
reticulate::virtualenv_create(envname = virtualenv_dir, python = python_path)
reticulate::virtualenv_install(virtualenv_dir, packages = PYTHON_DEPENDENCIES, ignore_installed = TRUE)
reticulate::use_virtualenv(virtualenv_dir, required = TRUE)

# call python functions
reticulate::source_python('functions.py')
```

```{r}
# wordcloud2 hack
wordcloud2a <- function (data, size = 1, minSize = 0, gridSize = 0, fontFamily = "AppleGothic", 
          fontWeight = "bold", color = "random-dark", backgroundColor = "white", 
          minRotation = -pi/4, maxRotation = pi/4, shuffle = TRUE, 
          rotateRatio = 0.4, shape = "circle", ellipticity = 0.65, 
          widgetsize = NULL, figPath = NULL, hoverFunction = NULL) {
  if ("table" %in% class(data)) {
    dataOut = data.frame(name = names(data), freq = as.vector(data))
  }
  else {
    data = as.data.frame(data)
    dataOut = data[, 1:2]
    names(dataOut) = c("name", "freq")
  }
  if (!is.null(figPath)) {
    if (!file.exists(figPath)) {
      stop("cannot find fig in the figPath")
    }
    spPath = strsplit(figPath, "\\.")[[1]]
    len = length(spPath)
    figClass = spPath[len]
    if (!figClass %in% c("jpeg", "jpg", "png", "bmp", "gif")) {
      stop("file should be a jpeg, jpg, png, bmp or gif file!")
    }
    base64 = base64enc::base64encode(figPath)
    base64 = paste0("data:image/", figClass, ";base64,", 
                    base64)
  }
  else {
    base64 = NULL
  }
  weightFactor = size * 180/max(dataOut$freq)
  settings <- list(word = dataOut$name, freq = dataOut$freq, 
                   fontFamily = fontFamily, fontWeight = fontWeight, color = color, 
                   minSize = minSize, weightFactor = weightFactor, backgroundColor = backgroundColor, 
                   gridSize = gridSize, minRotation = minRotation, maxRotation = maxRotation, 
                   shuffle = shuffle, rotateRatio = rotateRatio, shape = shape, 
                   ellipticity = ellipticity, figBase64 = base64, hover = htmlwidgets::JS(hoverFunction))
  chart = htmlwidgets::createWidget("wordcloud2", settings, 
                                    width = widgetsize[1], height = widgetsize[2], sizingPolicy = htmlwidgets::sizingPolicy(viewer.padding = 0, 
                                                                                                                            browser.padding = 0, browser.fill = TRUE))
  chart
}
```

Overview
=====================================

Row 
-----------------------------------------------------------------------
### Text Input {.no-title data-padding=15}
```{r}
textAreaInput(
  "text", 
  tags$div(
    HTML(paste(
      h4("Enter your text here:"), 
      tags$ul(tags$b("DO NOT "), 
              "use this dashboard as your workspace. You may lose your work.", 
              br(), "For accurate analysis, please", 
              tags$b("mark the end of each sentence"), 
              "with a punctuation mark (i.e., period, question mark, exclamation point)."), 
      hr()))), 
  rows = 10, width = "100%")

# show error messages when the input text is too short or doesn't include punctuation.
observeEvent(input$submit, {
  if (sum(str_detect(input$text, "[.!?]") == 0)) { # if number of punctuation is zero
    showNotification("Please use punctuation.", type = "warning")
  }
  if (str_length(input$text) < 10) { # if there are less than 10 characters
    showNotification("Please write more.", type = "info")
  }
})
```

### Info {.no-title data-padding=15}
```{r}
## title?
radioButtons("title", h4("Does the text include a title in the first line?", 
                         style = "margin-bottom: 2px;"), choices = c("No", "Yes"), inline = TRUE)

## select styles
checkboxGroupInput("style", h4("Which style(s) did you intend to use?", 
                               style = "margin-bottom: 2px;"), 
                   choices = c("polite", "deferential", "plain", "intimate"), inline = TRUE)

## select level
radioButtons("target", h4("What is your overall target level?", 
                          style = "margin-bottom: 2px;"), 
             choices = c("KOR102", "KOR105", "KOR107"), inline = TRUE)

actionButton("submit", "Let's Go!")
```

```{r}
# clean the text - remove any existing extra spaces
checked_text <- eventReactive(input$submit, {
  if (input$title == "Yes") {
    text_title <- str_extract(input$text, "^\\A.*")
    original_text <- str_replace(input$text, text_title, "")
    clean(original_text)
  } else {
    clean(input$text)
  }
})

# get title
text_title <- reactive(if (input$title == "Yes") str_extract(input$text, "^\\A.*"))

# POS-tag the text
tagged_text <- eventReactive(input$submit, {format_text(tag_text((checked_text())))})

# create data frame
text_df <- eventReactive(input$submit, {
  # tagged data
  tagged_col <- tibble(Tagged = tagged_text()) |> 
    separate_rows(Tagged, sep = "\\n") |> 
    mutate(Tagged = str_trim(Tagged)) |> # remove any extra spaces
    filter(Tagged != "\\n+" & Tagged != "\\s+" & Tagged != "") # remove any extra empty rows
  
  text_col <- tibble(Text = checked_text()) |>
    separate_rows(Text, sep = "(?<=\\.|!|\\?)") |>
    mutate(Text = str_trim(Text)) |> # remove any extra spaces
    filter(Text != "\\s+" & Text != "") # remove any extra empty rows

  # final data cols: Number, Text, Tagged-text
  text_col |> mutate(Number = 1:nrow(text_col)) |> bind_cols(tagged_col) |> 
    select(Number, Text, Tagged)
})

# create list of words
words_df <- eventReactive(input$submit, { 
  df <- data_df(checked_text())
  sub_df <- df |> mutate(NV = lag(Word), NI = lag(Index), NT = lag(Tag)) |>
    filter(Tag %in% c('XSA', 'XSV')) |>
    mutate(Word = paste0(NV, Word), Tag = paste0(NT, "-", Tag))
  cut_df <- df |> filter(!Index %in% sub_df$Index) |> filter(!Index %in% sub_df$NI)
  final <- sub_df |> select(Index, Word, Tag) |> bind_rows(cut_df) |> arrange(Index)
  final
  })

# number of content words
content_words = eventReactive(input$submit, {nrow(words_df())})

# number of sentences
num_sentences = eventReactive(input$submit, {sentences(tagged_text())})

# words per sentence
words_sentence <- eventReactive(input$submit, {round(content_words()/num_sentences(), 1)})

# lexical variety (unique words/total content words)
words_variety <- eventReactive(input$submit, {sttr(words_df())})

# number of connective endings (ECs) per sentence
sentence_complexity <- eventReactive(input$submit, {complexity(tagged_text())})

# number of transformative modifications (ETMs) per sentence
sentence_modifiers <- eventReactive(input$submit, {modifiers(tagged_text())})
```

Row
-----------------------------------------------------------------------
### Words
```{r}
renderValueBox({
  req(str_length(checked_text()) > 10 && sum(str_detect(checked_text(), "[.!>]")) > 0)
  valueBox(value = tags$p(content_words(), style = "font-size: 250%; margin-bottom: 0px;"), 
           caption = "Number of content words", icon = "fa-font")
})
```

### Sentences
```{r}
renderValueBox({
  req(str_length(checked_text()) > 10 && sum(str_detect(checked_text(), "[.!>]")) > 0)
  valueBox(value = tags$p(num_sentences(), style = "font-size: 250%; margin-bottom: 0px;"), 
           caption = "Number of sentences", icon = "fa-paragraph") 
  })
```

### Words per sentence
```{r}
renderValueBox({
  req(str_length(checked_text()) > 10 && sum(str_detect(checked_text(), "[.!>]")) > 0)
  valueBox(value = tags$p(words_sentence(), style = "font-size: 250%; margin-bottom: 0px;"), 
           caption = "Number of words per sentence", icon = "fa-pen")
})
```

Row
-----------------------------------------------------------------------
### Lexical Variety: Proportion of unique words
```{r}
renderGauge({
  req(str_length(checked_text()) > 10 && sum(str_detect(checked_text(), "[.!>]")) > 0)
  gauge(words_variety()*100, min = 0, max = 100, symbol = '%', 
      gaugeSectors(success = c(51, 100), warning = c(21, 50), danger = c(0, 20)))
})
```

### Sentence Complexity: Number of connectives per sentence
```{r}
renderGauge({
  req(str_length(checked_text()) > 10 && sum(str_detect(checked_text(), "[.!>]")) > 0)
  gauge(sentence_complexity(), min = 0, max = 2, 
        gaugeSectors(success = c(0.51, 2), warning = c(.31, 0.5), danger = c(0, .3))) 
})
```

### Noun Modification: Number of modifiers per sentence
```{r}
renderGauge({
  req(str_length(checked_text()) > 10 && sum(str_detect(checked_text(), "[.!>]")) > 0)
  gauge(sentence_modifiers(), min = 0, max = 2, 
        gaugeSectors(success = c(0.51, 2), warning = c(.21, 0.5), danger = c(0, .2))) 
})
```

Vocabulary {data-orientation=columns}
=====================================

Inputs {.sidebar}
-------------------------------------
```{r}
checkboxGroupInput("level", tags$p("Choose new target levels (optional):", 
                                   style = "margin-top: 10px"), 
                   choices = c("KOR102", "KOR105", "KOR107"))

sliderInput("size", "If the wordcloud doesn't show all the words, adjust to a smaller size:", 
            min = 0, max = 1.6, value = 0.6, step = 0.2)
```

Column {data-width=55%}
-------------------------------------
### New Words {.no-title}
```{r}
new_words <- reactive(if (class(vocab_list()) == "character") 0 else nrow(vocab_list()))

valueBox(value = tags$p(new_words(), style = "font-size: 250%; margin-bottom: 0px; "), 
         caption = "Number of new words", icon = "fa-plus", color = "info") |> 
  renderValueBox()
```

### Vocab WordCloud {.no-title}
```{r}
vocab_df <- reactive({
  read.csv('vocab_list.csv', 
           header = TRUE, encoding = 'UTF-8')
}) 

vocab_i <- reactive({
  if (length(input$level) == 0) {
    vocab_df() |> dplyr::filter(Level %in% input$target) # use the initially selected level
  } else {
    vocab_df() |> dplyr::filter(Level %in% input$level) # use the newly selected levels
  }
})

vocab_list <- reactive({
  result <- search_vocab_list(tagged_text(), vocab_i())
  if (class(result) == "character") { # if no result is found
    result
  } else {
    result <- result |> 
      rlang::set_names(c("Word", "Count")) |> 
      separate(Word, c("Level", "Word", "Lesson"), sep = ",")
    result # has Level, Word, Lesson, Count
  }
  return(result)
})

tangerine <- LaCroixColoR::lacroix_palette("Orange", n = 6, type = "discrete")
  
word_cloud_level <- reactive({
  validate(
      need(class(vocab_list()) != "character", "No words to display :(")
  )
  wordcloud2a(vocab_list()[,c("Word", "Count")], 
              color = rep_len(tangerine, nrow(vocab_list())), 
              rotateRatio = 0, size = input$size)
})

renderWordcloud2(word_cloud_level())
```

Column {data-width=45%}
-------------------------------------
### Vocab Table {.no-title}
```{r}
vocab_table <- reactive({
  validate(
      need(class(vocab_list()) != "character", "No result to display :(")
  )
  vocab_list() |> mutate(Level = paste(Level, Lesson, sep = "- "), 
                         Count = format(round(Count, 0)), .keep = "unused") |> 
    datatable( 
      class = "hover compact",
      extensions = "Buttons",
      options = list(
        dom = "Bftp",
        columnDefs = list(list(className = "dt-head-left", targets = 0:2)), 
        pageLength = -1, # -1 show all, a number shows that many rows per page
        pagingType = "simple", # https://datatables.net/reference/option/pagingType
        language = list(paginate = list('previous' = "«", 'next' = "»")),
        buttons = list(
        list(
          extend = "collection", # create a button that lists all
          text = "Show All",
          action = JS("function ( e, dt, node, config ) {
                      dt.page.len(-1);
                      dt.ajax.reload();
                      }"),
          className = "btn btn-new btn-sm"
          ), 
        list(
          extend = "collection", # create a button that returns to segments
          text = "Paginate",
          action = JS("function ( e, dt, node, config ) {
                      dt.page.len(20); 
                      dt.ajax.reload();
                      }"),
          className = "btn btn-new btn-sm"
          )),
        initComplete = JS("function () {
                        var btns = $('.dt-button');
                        btns.removeClass('dt-button');
                        $('.dataTables_filter').addClass('btn btn-search btn-sm');
                        $('.dataTables_paginate > .pagination a').addClass('btn btn-page btn-sm');
                        $('.dataTables_length').addClass('btn btn-new-search btn-sm');
                        $('.dataTables_length select').addClass('btn btn-search btn-sm');
                        }")),
      fillContainer = TRUE) |>  # enable scrolling within the table
    formatStyle( # show bars according to count
      vocab_list()$Count, 
      background = styleColorBar(vocab_list()$Count, '#F8D961'),
      backgroundSize = '70% 60%', # width %, height %
      backgroundRepeat = 'no-repeat',
      backgroundPosition = 'right')
})

DT::renderDT(vocab_table()) 
```

Grammar {data-orientation=columns}
=====================================
Inputs {.sidebar}
-------------------------------------
```{r}
checkboxGroupInput("level2", tags$p("Choose new target levels (optional):", 
                                   style = "margin-top: 10px"), 
                   choices = c("KOR102", "KOR105", "KOR107"))
```

Column {data-width=60%}
----------------------------------
### `r renderText(text_title())`
```{r}
grammar_df <- reactive({
  read.csv('grammar_list.csv', 
           header = TRUE, encoding = 'UTF-8')
}) 

grammar_i <- reactive({
  if (length(input$level2) == 0) {
    grammar_df() |> dplyr::filter(Level %in% input$target)
  } else {
    grammar_df() |> dplyr::filter(Level %in% input$level2) # other levels selected
  }
})

used_list <- reactive({
  gr_patterns <- as.vector(grammar_i()$Pattern) |> 
    lapply(function(x) str_detect(text_df()$Tagged, x)) |> 
    as.data.frame(col.names = grammar_i()$No)
  if (any(gr_patterns) == FALSE) {
    gr_final <- text_df() |> select(Number, Text) |> add_column(Grammar = "")
  } else {
    gr_results <- text_df() |> bind_cols(gr_patterns)
    gr_list <- lapply(3:length(gr_results), function(x) gr_results[,c(2,x)])
    gr_extract <- lapply(1:length(gr_list), function(x) gr_list[x] |> as.data.frame() |> 
                filter(gr_list[[x]][[2]] == TRUE))
    gr_used <- sapply(1:length(gr_extract), function(x) if (nrow(gr_extract[[x]] != 0)) paste0(names(gr_extract[[x]])[[2]], "\t", gr_extract[[x]][[1]])) |> 
    unlist()
    gr_final <- gr_used |> as_tibble() |> 
      separate(1, into = c("No", "Text"), sep = "\t")
  }
  return(gr_final)
})

grammar_c <- reactive({
  grammar_i() |> select(No, Grammar) |> distinct()
})

text_grammar <- reactive({
    text_gr <- text_df() |> left_join(used_list(), by = "Text") |> 
      left_join(grammar_c()) |> 
      mutate(ID = str_extract(No, "[A-Z]\\.[A-Z][0-9]+\\.[0-9](\\.\\.[A-Z][0-9]+\\.[0-9])?")) |> 
      mutate(Used = paste(ID, Grammar)) |> 
      select(Text, Used) |>
      mutate(Used = str_replace_all(Used, "NA", "")) |>
      mutate(Used = str_replace(Used, "\\.\\.", "/"))

    text_gr <- data.table::setDT(text_gr)[,Label:=.GRP, by = "Text"]
    # number distinct text lines to arrange in the order they appear

    text_gr <- text_gr |> group_by(Text, Label) |>
      summarize(Grammar = paste(Used, collapse = ",")) |>
      arrange(Label) |> select(Label, Text, Grammar) |>
      mutate(Text = paste(Label, Text, sep = ": ")) |>
      select(Text, Grammar) |>
      separate_rows(Grammar, sep = ",")
})

text_list <- reactive({
  # remove header
  headerCallback <- c(
    "function(thead, data, start, end, display){",
    "  $('th', thead).css('display', 'none');",
    "}"
  )
  
  text_grammar() |> mutate(Grammar = substr(Grammar, 3, 50)) |> 
    datatable(
    class = "compact hover",
    extensions = c("RowGroup", "Buttons"),
    options = list(
      dom = "Bftp",
      columnDefs = list(list(visible = FALSE, targets = c(0,1))), # group by text line
      headerCallback = JS(headerCallback),
      pageLength = -1,
      pagingType = "full", # https://datatables.net/reference/option/pagingType
      language = list(paginate = list('previous' = "«", 'next' = "»")),
      rowGroup = list(dataSrc = 1,
                      startRender = JS("function(rows, group) {", 
                                       "  var style = 'background-color: rgba(39, 128, 227, 0.1);';",
                                       "  var td = `<td style='${style}'>${group}</td>`;",
                                       "  return $(`<tr>${td}</tr>`);",
                                       "}")), 
      buttons = list(
        list(
          extend = "collection", 
          text = "Show All",
          action = JS("function ( e, dt, node, config ) {
                      dt.page.len(-1);
                      dt.ajax.reload();
                      }"),
          className = "btn btn-new btn-sm"
          ), 
        list(
          extend = "collection", 
          text = "Paginate",
          action = JS("function ( e, dt, node, config ) {
                      dt.page.len(12);
                      dt.ajax.reload();
                      }"),
          className = "btn btn-new btn-sm"
          )),
      initComplete = JS("function () {
                        var btns = $('.dt-button');
                        btns.removeClass('dt-button');
                        $('.dataTables_filter').addClass('btn btn-search btn-sm');
                        $('.dataTables_paginate').addClass('btn btn-page btn-sm');
                        $('.dataTables_paginate > .pagination a').addClass('btn btn-page btn-sm');
      }")),
    selection = "none", 
    fillContainer = TRUE)
})

DT::renderDT(text_list())
```

Column {data-width=40%}
----------------------------------
### Grammar {.no-title}
```{r}
grammar_used <- reactive({
  text_grammar() |> filter(str_detect(Grammar, "^\\w")) |> 
    group_by(Grammar) |> summarize(Count = n())
  })

grammar_table <- reactive({
  grammar_used() |> 
    separate(Grammar, into = c("Level", "ID"), sep = "(?<=[A-Z])\\.") |> 
    mutate(Level = str_replace_all(Level, "B", "Beginning"), 
           Level = str_replace_all(Level, "I", "Intermediate")) |> 
    datatable(
      class = "hover compact", 
      extensions = c("RowGroup", "Buttons"),
      options = list(
        dom = "Btp", 
        columnDefs = list(list(className = "dt-left", targets = 0:3), 
                          list(visible = FALSE, targets = 1)),
        pageLength = -1, 
        pagingType = "simple", # https://datatables.net/reference/option/pagingType
        language = list(paginate = list('previous' = "«", 'next' = "»")),
        rowGroup = list(dataSrc = 1,
                      startRender = JS("function(rows, group) {", 
                                       "  var style = 'background-color: #ededed;';" ,
                                       "  var td = `<td style='${style}' colspan=12>${group}</td>`;",
                                       "  return $(`<tr>${td}</tr>`);",
                                       "}")), 
        buttons = list(
        list(
          extend = "collection", 
          text = "Show All",
          action = JS("function ( e, dt, node, config ) {
                      dt.page.len(-1);
                      dt.ajax.reload();
                      }"),
          className = "btn btn-new btn-sm"
          ), 
        list(
          extend = "collection", 
          text = "Paginate",
          action = JS("function ( e, dt, node, config ) {
                      dt.page.len(18);
                      dt.ajax.reload();
                      }"),
          className = "btn btn-new btn-sm"
          ))),
      fillContainer = TRUE) |> 
    formatStyle(
      grammar_used()$Count,
      background = styleColorBar(grammar_used()$Count, '#B6D944'),
      backgroundSize = '70% 60%',
      backgroundRepeat = 'no-repeat',
      backgroundPosition = 'right')
})
  
DT::renderDT({
  validate(
      need(nrow(grammar_used()) > 0, "No results to display :(")
  )
  grammar_table()
  })
```


Summary
=====================================

Column {.tabset .tabset-fade}
----------------------------------
### Vocab & Grammar 
```{r}
comment_vocab <- reactive({
  heading <- paste0("<li class = 'new'>Your vocabulary variety score is <b>", 
                    words_variety(), "</b>, ")
  ending <- "% of all the words used were unique.</li>"
  if (words_variety() <= .3) {
    paste0(heading, "which means only", words_variety() *100, ending)
  } else if (words_variety() > .3 & words_variety() < .5) {
    paste0(heading, "which means", words_variety() *100, ending)
  } else if (words_variety() >= .5 & words_variety() < .9) {
    paste(heading, "which means", words_variety() *100, ending)
  } else if (words_variety() >= .9) {
    paste(heading, "which means", words_variety() *100, ending, 
          "<li class = 'new'>If you have more than 100 words, 
          you might want to check if there are lots of spelling errors, 
          as it is rare to reach such high percentage.</li>")
  }
})

comment_new_words <- reactive({
  if (class(vocab_list()) == "character") {
    paste("<li class = 'new'>You use d<b>no new words</b> from the level you have selected. :(</li>")
  } else {
    paste("<li class = 'new'>You used<b>", nrow(vocab_list()), "new words</b> from the level you have selected.</li>")
  }
})

vocab_plot <- reactive({
  df <- words_df() |> 
    mutate(New_Tag = str_replace(Tag, "NN.", "NOUN"), 
           New_Tag = str_replace(New_Tag, ".+V$", "VERB"), 
           New_Tag = str_replace(New_Tag, ".+A$", "ADJECTIVE"), 
           #New_Tag = str_replace(New_Tag, "XR", "ADJECTIVE"), 
           New_Tag = str_replace(New_Tag, "VC.", "COPULA"), 
           New_Tag = str_replace(New_Tag, "MA.", "ADVERB"), 
           New_Tag = str_replace(New_Tag, "VX", "AUXILIARY")) |> 
    mutate(New_Tag = factor(New_Tag, 
                            levels = c("COPULA", "AUXILIARY", "ADVERB","ADJECTIVE", "VERB", "NOUN"))) |> group_by(New_Tag) |> 
    summarize(Count = n(), Percentage = round(Count*100/nrow(words_df()), 0))
  
  plot <- df |> ggplot(aes(x = Percentage, y = New_Tag, group = New_Tag)) + 
    geom_bar(width = .05, stat = "identity", fill = "#34495e", color = "#34495e") + 
    geom_point(aes(color = New_Tag), shape = 21, size = 10, fill = "white") + 
    geom_text(aes(label = Count), color = "#444444", fontface = "bold", size = 4) +
    labs(x = "Percentage (Count in circle)", y = "") + 
    scale_x_continuous(expand = c(0, 0), limits = c(0, 80)) + 
    theme(legend.position = "none", axis.ticks = element_blank(), 
          panel.grid.minor.x = element_line(linetype = "dashed"), 
          panel.grid.major.y = element_blank(), plot.margin = margin(10, 10, 200, 10))
  cowplot::plot_grid(vocab_plot(), NULL, rel_widths = c(1, 1.2))
})

comment_complexity <- reactive({
  if (sentence_complexity() < .2) {
    paste("<li class = 'new'>Your grammar complexity score indicates that 
          almost all the sentences are simple sentences without connectives, dependent clauses, compound verbs, etc.
          <br>Consider combining two or sentences to create more complex sentences.</li>")
  } else if (sentence_complexity() >= .2 & sentence_complexity() < .5) {
    paste("<li class = 'new'>Your grammar complexity score indicates that 
          you have few complex sentences.<br>Consider using more connectives, noun modifying forms.</li>")
  } else if (sentence_complexity() >= .5 & sentence_complexity() <= 1 && input$target == "KOR102") {
    paste("<li class = 'new'>Your grammar complexity score indicates that 
          you have a good number of complex sentences.<br>Keep up the good work!</li>")
  } else if (sentence_complexity() >= .5 & sentence_complexity() <= 1 && input$target == "KOR105") {
    paste("<li class = 'new'>Your grammar complexity score indicates that 
          you have a moderate number of complex sentences, but you would want to increase this number in the future.</li>")
  } else if (sentence_complexity() >= .5 & sentence_complexity() <= 1 && input$target == "KOR107") {
    paste("<li class = 'new'>Your grammar complexity score indicates that 
          you have a moderate number of complex sentences, but this is a little low to say you are a strong Korean language user at this level.</li>")
  } else if (sentence_complexity() >= 1) {
    paste("<li class = 'new'>Your grammar complexity score indicates that 
          you have a good number of complex sentences, demonstrating that you are a strong Korean language user.</li>")
    }
  })

comment_modifiers <- reactive({
  if (sentence_modifiers() < .2) {
    paste("<li class = 'new'>Your text includes almost no noun-modifying adjectives or verbs, 
          which can make your Korean sound very elementary.
          <br>Consider using more adjectives and adding explanations to nouns/noun phrases.</li>")
  } else if (sentence_modifiers() >= .2 & sentence_modifiers() < .5) {
    paste("<li class = 'new'>Your text includes little noun-modifying adjectives or verbs.
          <br>This suggests that your Korean is elementary and/or you are not providing enough details.
          <br>Adding more descriptions would be great!</li>")
  } else if (sentence_modifiers() >= .5 & sentence_modifiers() <= 1) {
    paste("<li class = 'new'>Your text includes a good number of noun-modifying adjectives or verbs, which makes your Korean sound more sophisticated.
          <br>It is likely that you are providing enough descriptions in your writing.
          <br>If you are studying at an advanced level and/or writing a genre that requires description/exposition, you would want to push this number to around 1.5.</li>")
    }
  })

comment_wps <- reactive({
  heading <- paste0("<li class = 'new'>The average number of words per sentence in this text is <b>", words_sentence(), "</b>, ")
  if (words_sentence() < 5) {
    paste0(heading, "which sounds curt for your level!</li>")
  } else if (words_sentence() >= 5 & words_sentence() < 8) {
    paste0(heading, "which sounds okay for your level. If you have low sentence complexity and few modifiers, working on those will naturally increase the sentence lengths!</li>")
  } else if (words_sentence() >= 8 & words_sentence() < 15) {
    paste0(heading, "which sounds good for your level.</li>")
  } else if (words_sentence() >= 15) {
    paste0(heading, "which seems too high. See if you have missed any punctuation, or break up sentences that are too long to enhance clarity!</li>")
  }
})

comment_new_grammar <- reactive({
  if (nrow(grammar_used()) > 0) {
    paste0("<li class = 'new'>You have used <b>", nrow(grammar_used()), " different new grammar points</b> from the level you have selected.</li>")
  } else {
    paste0("<li class = 'new'>You have used <b>no new grammar points</b> from the level you have selected. :(</li>")
  }
})

comment_table_vg <- reactive({
  paste0("
  <table style = 'width: 90%'>
  <tr>
  <td width = '50%'>
  <h3 style = 'color: black;'>Vocabulary</h3>
  <p class = 'color1'></p><ul>", 
  comment_vocab(), comment_new_words(), 
  "<li class = 'new'>Scroll down to see the composition of all the words used in your text!</li></ul></td>
  <td width = '50%'>
  <h3 style = 'color: black;'>Grammar</h3>
  <p class = 'color2'></p><ul>", 
  comment_complexity(), comment_modifiers(), comment_wps(), comment_new_grammar(),
  "</ul></td>
  </tr>
  <tr>
  <td colspan = '2'>
  Note: These comments only rely on linguistic characteristics found in your text. While they may provide <i>some</i> pointers regarding how you are using the language, remember that they do not speak to the quality of your writing, especially the content, organization, clarity, etc.
  </td>
  </tr>
  </table>"
  )
})

renderUI(HTML("<br>", comment_table_vg()), outputArgs = list(inline = TRUE))
renderPlot(vocab_plot())
```

### Style & Others
```{r}
style_check <- reactive({
  if (length(input$style) > 0) {
    styles <- paste(input$style, collapse = " and ")
    heading <- paste0("<li class = 'new'>You indicated that you have used: <b>", styles, " style</b>.</li>")
    if (input$style == "polite") {
      paste0(heading, "<li>We checked if your text includes any sentences that lack the -어/아요 ending.</li>")
    } else if (input$style == "deferential") {
      paste0(heading, "<li>We checked if your text includes any sentences that lack endings -ㅂ/습니다, -ㅂ/습니까?.</li>")
    } else if (any(input$style %in% c("plain", "intimate"))) {
      paste0(heading, "<li>We checked your text for appropriate endings and personal pronoun agreement.</li>")
    }
  } else {
    paste0("<li class = 'new'>You have not selected any style. No worries! You can skip it, or simply go back to the first page to check all that applies, then hit the 'Let's Go!' button again.")
  }
})

comment_style <- reactive({
  if (length(input$style) > 0) {
    if (is.null(ending_check()) == TRUE && is.null(pronoun_check()) == TRUE &&
        is.null(plain_check()) == TRUE && is.null(polite_check()) == TRUE && 
        is.null(deferential_check()) == TRUE) {
      paste("<li class = 'new'>Great! No outstanding issue has been detected!</li>")
    } else {
      paste(polite_check(), deferential_check(), ending_check(), pronoun_check(), plain_check())
    }
  }
})

# mixing polite style with other styles unless polite style is included
ending_errors <- reactive({
  if (any(!(input$style %in% c("plain", "intimate"))) == FALSE) { 
    # if selected any of these styles check if there are any polite endings present
    text_df() |> filter(str_detect(Tagged, "[요죠]/EF")) |> 
      select(Number) |> unlist()
  }
})

ending_check <- reactive({
  if (length(ending_errors()) > 0) {
    paste0("<li class = 'new'>Oops...! You have used the polite ending <b>", 
           length(ending_errors()), "</b> time(s) in your text. 
           Check <i>sentence #", paste(ending_errors(), collapse = ", "), "</i> 
           and see if you did this by mistake.</li>")
  }
})

polite_check  <- reactive({
  if (input$style == "polite") { 
    # if selected any of these styles check if there are any polite endings present
    pol <- text_df() |> filter(!str_detect(Tagged, "[요죠]/EF")) |> 
      select(Number) |> unlist()
    if (length(pol) > 0) {
      paste0("<li class = 'new'>Oops...! You have didn't use the denferential ending <b>",
             length(pol), "</b> time(s) in your text. 
             Check <i>sentence #", paste(pol, collapse = ", "), "</i> 
             and see if you did this by mistake.</li>")
    }
  }
})

deferential_check  <- reactive({
  if (input$style == "deferential") { 
    # if selected any of these styles check if there are any polite endings present
    def <- text_df() |> filter(!str_detect(Tagged, "니[다까]/EF")) |> 
      select(Number) |> unlist()
    if (length(def) > 0) {
      paste0("<li class = 'new'>Oops...! You have didn't use the denferential ending <b>",
             length(def), "</b> time(s) in your text. 
             Check <i>sentence #", paste(def, collapse = ", "), "</i> 
             and see if you did this by mistake.</li>")
    }
  }
})

# using humble pronouns with plain or intimate style
pronoun_errors <- reactive({
  plain_singular <- str_detect(text_df()$Tagged, 
                               "(?<=(저/NP|제가/NNP|제/XPN))[^.!?]+ ([는ㄴ]?다|니|자|[어아]?라)/EF")
  plain_plural <- str_detect(text_df()$Tagged, 
                             "(?<=저희/NP)[^.!?]+ ((는ㄴ)?다|니|자|[어아]?라)/EF")
  intimate_singular <- str_detect(text_df()$Tagged, 
                                  "(?<=(저/NP|제가/NNP|제/XPN))[^.!?]+ [^요]/EF")
  intimate_plural <- str_detect(text_df()$Tagged, 
                                "(?<=저희/NP)[^.!?]+ [^요]/EF")
  singular <- tibble(plain = plain_singular, intimate = intimate_singular)
  singular$total <- rowSums(singular)
  singular[singular == 2] <- 1
  plural <- tibble(plain = plain_plural, intimate = intimate_plural)
  plural$total <- rowSums(plural)
  plural[plural == 2] <- 1

  sum(singular$total) + sum(plural$total)
  })

pronoun_check <- reactive({
  if (pronoun_errors() > 0) {
    paste0("<li class = 'new'>Hmm... You have used humble pronouns with the plain/intimate style <b>", pronoun_errors(), " time(s)</b>.
           <br>Unless you are directly quoting someone, use the plain pronouns 나 and 우리 to match the plain style and intimate style. There's no need to make yourself humble with this style!</li>")
  } 
})

plain_check <- reactive({
  va <- text_df() |> 
    filter(
      str_detect(Tagged, 
                 "((?<!(없|있))/VA|XSA|VCP|VCN|(싶|있)/VX) (시/EP )?([었았]/EP )?[는ㄴ은]다/EF")) |> 
    select(Number) |> unlist()
  vv <- text_df() |> 
    filter(
      str_detect(Tagged, 
                 "(VV|(?<!(싶|있))/VX|XSV|없/VA|[밌있]/VA) (시/EP )?다/EF")) |>
    select(Number) |> unlist()
  vv_ep <- text_df() |> 
    filter(
      str_detect(Tagged, 
                 "(VV|(?<!(싶|있))/VX|XSV|없/VA|[밌있]/VA) (시/EP )?([었았]/EP )[는ㄴ]다/EF")) |>
    select(Number) |> unlist()
  
  if (length(va) > 0 | length(vv) > 0 | length(vv_ep) > 0) { # if any error is present
      if (length(va) == 0 | length(vv_ep) > 0) { # no adj error, only verb errors
        paste0("<li class = 'new'>It appears that you have incorrect conjugations with the plain ending with verbs: Look at <i>sentence #", paste(sort(c(vv, vv_ep)), collapse = ", "), "</i>.</li>
               <ul><li class = 'new'><span style='background-color: #E9E4A6'>Quick note:</span>
                <b>Verb stems</b> combine with <b>는</b>다 (consonant-ending stem) or 
               <b>ㄴ</b>다 (vowel-ending stem) in the present tense. 
               For past tense, just add (었/았)다!</li></ul>")
      } else if (length(vv) == 0 && length(vv_ep) == 0) { # only adjective errors
        paste0("<li class = 'new'>It appears that you have incorrect conjugations with the plain ending with adjectives/Copula/있다/없다: Look at <i>sentence #", paste(va, collapse = ", "), "</i>.</li>
               <ul><li class = 'new'><span style='background-color: #E9E4A6'>Quick note:</span> 
              For these types of predicates, simply combine the stem with 다.</li></ul>")
      } else if (length(vv) > 0 && length(vv_ep) > 0 && length(va) > 0) {
        paste0("<li>It appears that you are a little confused about conjugations!</li>
               <li>Verbs: Look at <i>sentence #", paste(sort(c(vv, vv_ep)), collapse = ", "), "</i>.</li>
               <ul><li class = 'new'><span style='background-color: #E9E4A6'>Quick note:</span> 
              <b>Verb stems</b> combine with <b>는</b>다 (consonant-ending stem) or <b>ㄴ</b>다 (vowel-ending stem) in the present tense.</li>
               <li class = 'new'>For past tense, just add (었/았)다!</li></ul>", 
               "<li class = 'new'>Adjectives/Copula/있다/없다: Look at <i>sentence #", 
               paste(va, collapse = ", "), "</i>.</li>
               <ul><li class = 'new'><span style='background-color: #E9E4A6'>Quick note:</span> 
              For these types of predicates, simply combine the stem with 다.</li></ul>")
      }
  } 
})

comment_table_st <- reactive({
  paste0("
  <table style = 'width: 90%'>
  <tr>
  <td width = '50%'>
  <h3 style = 'color: black;'>Style</h3>
  <p class = 'color3'></p><ul>", 
  style_check(), 
  "</ul></td>
  <td width = '50%'>
  <h3 style = 'color: black;'>Style Use</h3>
  <p class = 'color4'></p><ul>", 
  comment_style(), 
  "</ul></td>
  </tr>
  </table>"
  )
})

#---

comment_mechanics <- reactive({
  if (is.null(particle_check()) == TRUE && is.null(comma_errors()) == TRUE &&
      is.null(punctuation_errors()) == TRUE && is.null(conjunction_errors()) == TRUE &&
      is.null(colon_errors()) == TRUE) {
    paste("<li class = 'new'>We checked the use of punctuation according to Korean writing convention.</li><li>Good news! No outstanding issue has been detected!</li>")
  } else {
    paste(particle_check(), comma_errors(), punctuation_errors(), conjunction_errors(), colon_errors())
  }
})

comment_common <- reactive({
  if (is.null(common_one()) == TRUE && is.null(common_two()) == TRUE && 
      is.null(common_three()) == TRUE) {
    paste("<li class = 'new'>We checked for some of the common phrasal mistakes made by beginning-intermediate level learners.</li><li>Great! No outstanding issue has been detected :)</li>")
  } else {
    paste(common_one(), common_two(), common_three())
  }
})

## using conjunctions within the sentence
conjunction_errors <- reactive({
  conj <- text_df() |> 
    filter(str_detect(
      Tagged, "((?<!SP)\\s그리고|\\s그러나|\\s그런데|\\s그렇지만|\\s그래서|\\s왜냐면|\\s왜냐하면|\\s그러니까)") | str_detect(Tagged, "(?<!J[K|X].?)\\s하지만")) |> 
    select(Number) |> unlist()
  if (length(conj) > 0) {
    paste("<li class = 'new'>You have used conjunctions", length(conj), 
          "times without ending a sentence in <i>sentence #", paste(conj, collapse = ", "), "</i>.<br>
          In Korean, you either have to use connective such as -고, -지만, -어서/아서 to connect two clauses within a sentence, or end the sentence then start a new sentence with the conjunction.</li>")
  }
})

punctuation_errors <- reactive({
  punc <- text_df() |> 
    filter(str_detect(Tagged, "(그리고|그러나|그런데|그렇지만|하지만|그래서|왜냐면|왜냐하면|그러니까|그럼)/\\w+ ,/SP")) |> 
    select(Number) |> unlist()
  if (length(punc) > 0) {
    paste("<li class = 'new'>You have placed a comma after conjunctions <b>", length(punc), 
          "times</b>, in sentence #", paste(punc, collapse = ", "), 
          ".<br> This is uncommon in written Korean.<br>Consider removing them unless you are indicating that there should be a pause when reading.</li>")
  }
})

colon_errors <- reactive({
  colon <- str_count(text_df()$Tagged, "[^(SN)] [:;]")
  if (any(colon > 0)) {
    paste("<li class = 'new'>You used a colon in your writing. Korean writing convention does not utilize colon to add a sentence.</li>")
  }
})

comma_errors <- reactive({
  comma <- sum(str_detect(text_df()$Tagged, ",/SP"))
  if (comma/words_sentence() >= .7) {
      paste("<li class = 'new'>It seems like you are using commas too often. Korean writing convention does not utilize comma after a short phrase.</li>")
  }
})

# check on particles
particle_check <- reactive({
  jx <- mean(str_count(text_df()$Tagged, ".J\\w+"))
  if (jx < 1.2) {
    paste("<li class = 'new'>Your text seems to include too few particles. You are encouraged to include subject and object particles.</li>")
  }
})

## writing 제 제일 좋아하는
common_one <- reactive({
  myfav <- text_df() |> 
    filter(str_detect(Tagged, "제/XPN (제일/NNG )?좋아하/VV")) |> 
    select(Number) |> unlist()
  
  if (length(myfav) > 0) {
    paste("<li class = 'new'>You have said '제 (제일) 좋아하는' in sentences #", paste(myfav, collapse = ", "), 
          ".<br>In Korean we say '[NOUN] <i>that I like the most</i>', which would be '제가 제일 좋아하는 [NOUN]'. Word-to-word equivalent of 'my favorite' doesn't exist in Korean.</li>")
  }
})

## 기 후/다음
common_two <- reactive({
  aftering <- text_df() |> 
    filter(str_detect(Tagged, "기/ETN (다음|후)/\\w+\\s(?!으로)")) |> 
    select(Number) |> unlist()
  
  if (length(aftering) > 0) {
    paste("<li class = 'new'>You have said 'VERB기 다음/후' in sentences #", paste(aftering, collapse = ", "), 
          ".<br>If you are saying '<i>after -ing</i>, '[VERB](으)ㄴ 다음/후 is the correct form in Korean.</li>")
  }
})

## 에 이사하다
common_three <- reactive({
  move <- text_df() |> 
    filter(str_detect(Tagged, "에/JKB 이사/NNG 하/XSV")) |> 
    select(Number) |> unlist()
  
  if (length(move) > 0) {
    paste0("<li class = 'new'>You have said '에 이사하다' in <i>sentences #", paste(move, collapse = ", "), "</i>.<br>If you are saying 'to move to somewhere', the correct particle would be (으)로, not 에.</li>")
  }
})

comment_table_ot <- reactive({
  paste0("
  <table style = 'width: 90%'>
  <tr>
  <td width = '50%'>
  <h3 style = 'color: black;'>Mechanics</h3>
  <p class = 'color5'></p><ul>", 
  comment_mechanics(),
  "</ul></td>
  <td width = '50%'>
  <h3 style = 'color: black;'>Common Errors</h3>
  <p class = 'color6'></p><ul>", 
  comment_common(), 
  "</ul></td>
  </tr>
  </table>"
  )
})

renderUI(HTML("<br>", comment_table_st(), "<br>", comment_table_ot()))
```

### WordCloud 
```{r}

sliderInput("wcsize", "Adjust size:", min = 0.6, max = 2, value = 1, step = 0.2, ticks = FALSE)

col_list <- reactive(c("Apricot", "Berry", "CeriseLimon", "CranRaspberry", "Lime", "Mango",
                         "Orange","PassionFruit", "PeachPear"))

# generate data table for WordCloud
word_list <- eventReactive(input$submit, {text_wc(words_df())})

col_pal <- reactive({
  LaCroixColoR::lacroix_palette(col_list()[sample.int(9, 1)], n = 12, type = "continuous")
  })

wc_download <- reactive({
  wordcloud2a(word_list(), 
              color = rep_len(col_pal(), nrow(word_list())), # this allows giving color to every word
              size = input$wcsize, rotateRatio = 0, ellipticity = .4)
})

renderWordcloud2(wc_download())
```


About
=====================================

Did you run into any errors while using the app? Do you have suggestions or complaints?  

```{r}
mailtoR(email = "koreantextanalyzer@gmail.com",
           text = "Click here to send an email.", 
           subject = "korta")
 
use_mailtoR()
```

